# Sign-Language-DetectorğŸ–ï¸

A simple deep learning project for classifying American Sign Language (ASL) hand gestures using TensorFlow and OpenCV.

## ğŸ“¦ Requirements

- Python 3.8+
- TensorFlow
- OpenCV
- NumPy

Install dependencies:
```bash
pip install tensorflow opencv-python numpy

ğŸ§  Project Overview
This project trains a Convolutional Neural Network (CNN) to recognize ASL hand signs from grayscale images. The model is trained on a dataset of labeled hand gesture images and saved for future use.

ğŸ“ Project Structure
sign-language-project/
â”‚
â”œâ”€â”€ train_model.py         # Train and save the model
â”œâ”€â”€ detect_sign.py         # Run live prediction using webcam
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ asl_model.h5       # Trained model
â”‚   â””â”€â”€ labels.txt         # Class labels
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ asl data/          # Training images (folders per letter)


ğŸš€ How to Use
1. Train the Model
python train_model.py


- Loads images from dataset/asl data
- Converts them to grayscale and resizes to 64x64
- Builds and trains a CNN model
- Saves the model to model/asl_model.h5

2. Run Live Detection (Optional)
python detect_sign.py
- Opens webcam
- Captures hand gesture
- Predicts the corresponding ASL letter
- Displays result on screen

ğŸ“š Files Explained
- train_model.py: Loads and preprocesses data, trains the CNN model.
- detect_sign.py: Loads the trained model and performs live prediction using webcam.
- model/asl_model.h5: Saved model after training.
- model/labels.txt: List of class labels used during training.

ğŸ’¡ Notes
- Make sure the dataset is organized with one folder per ASL letter inside dataset/asl data.
- Images should be .png format and clearly show the hand gesture.
- The model expects grayscale images resized to 64x64 pixels.




